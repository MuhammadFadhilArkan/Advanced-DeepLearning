{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Multi-GPU Mirrored Strategy.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOaaWY9UfO9gRMN5QdOu1If"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9Ui0BWPPZLfs","executionInfo":{"status":"ok","timestamp":1633923347140,"user_tz":-420,"elapsed":2069,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import os"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W5bJC6SYZkpm"},"source":["Setup Distribution Strategy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eK-cRviyZi2D","executionInfo":{"status":"ok","timestamp":1633923352636,"user_tz":-420,"elapsed":335,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"aa752a00-19c4-44c0-b012-bc21ea85aada"},"source":["# Note that it generally has a minimum of 8 cores, but if your GPU has\n","# less, you need to set this. In this case one of my GPUs has 4 cores\n","os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n","\n","# If the list of devices is not specified in the\n","# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n","# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\n","strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n","print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","Number of devices: 1\n"]}]},{"cell_type":"markdown","metadata":{"id":"OR4YKmgYZyJc"},"source":["Prepare the Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfZUzDNvZiyz","executionInfo":{"status":"ok","timestamp":1633923354769,"user_tz":-420,"elapsed":2152,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"f2e74e85-cb2e-4d17-b208-4926399f695c"},"source":["# Get the data\n","fashion_mnist = tf.keras.datasets.fashion_mnist\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# Adding a dimension to the array -> new shape == (28, 28, 1)\n","# We are doing this because the first layer in our model is a convolutional\n","# layer and it requires a 4D input (batch_size, height, width, channels).\n","# batch_size dimension will be added later on.\n","train_images = train_images[..., None]\n","test_images = test_images[..., None]\n","\n","# Normalize the images to [0, 1] range.\n","train_images = train_images / np.float32(255)\n","test_images = test_images / np.float32(255)\n","\n","# Batch the input data\n","BUFFER_SIZE = len(train_images)\n","BATCH_SIZE_PER_REPLICA = 64\n","GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n","\n","# Create Datasets from the batches\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n","\n","# Create Distributed Datasets from the datasets\n","train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n","test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"xtJYuQp6Z9Cz"},"source":["Define the Model\n"]},{"cell_type":"code","metadata":{"id":"fw6Rp45XZivU","executionInfo":{"status":"ok","timestamp":1633923354778,"user_tz":-420,"elapsed":29,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["# Create the model architecture\n","def create_model():\n","  model = tf.keras.Sequential([\n","      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","      tf.keras.layers.MaxPooling2D(),\n","      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n","      tf.keras.layers.MaxPooling2D(),\n","      tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(64, activation='relu'),\n","      tf.keras.layers.Dense(10)\n","    ])\n","  return model"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tVya3OYNaAaF"},"source":["Configure custom training\n","\n","Instead of model.compile(), we're going to do custom training, so let's do that within a strategy scope.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8LOpCWUZiqa","executionInfo":{"status":"ok","timestamp":1633923354779,"user_tz":-420,"elapsed":25,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"29fe43ef-7195-43aa-c6f2-5b235c56c77b"},"source":["with strategy.scope():\n","    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\n","    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\n","    # Remember -- the map reduce is how the losses get aggregated\n","    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n","\n","    def compute_loss(labels, predictions):\n","        # Compute Loss uses the loss object to compute the loss\n","        # Notice that per_example_loss will have an entry per GPU\n","        # so in this case there'll be 2 -- i.e. the loss for each replica\n","        per_example_loss = loss_object(labels, predictions)\n","        # You can print it to see it -- you'll get output like this:\n","        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n","        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\n","        print(per_example_loss)\n","        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n","\n","    # We'll just reduce by getting the average of the losses\n","    test_loss = tf.keras.metrics.Mean(name='test_loss')\n","\n","    # Accuracy on train and test will be SparseCategoricalAccuracy\n","    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","\n","    # Optimizer will be Adam\n","    optimizer = tf.keras.optimizers.Adam()\n","\n","    # Create the model within the scope\n","    model = create_model()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZKwVX1WAabXN"},"source":["Train and Test Steps Functions\n"]},{"cell_type":"code","metadata":{"id":"nTcJB8zpZimb","executionInfo":{"status":"ok","timestamp":1633923354780,"user_tz":-420,"elapsed":18,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["# `run` replicates the provided computation and runs it\n","# with the distributed input.\n","@tf.function\n","def distributed_train_step(dataset_inputs):\n","  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n","  #tf.print(per_replica_losses.values)\n","  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n","\n","def train_step(inputs):\n","  images, labels = inputs\n","  with tf.GradientTape() as tape:\n","    predictions = model(images, training=True)\n","    loss = compute_loss(labels, predictions)\n","\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_accuracy.update_state(labels, predictions)\n","  return loss\n","\n","#######################\n","# Test Steps Functions\n","#######################\n","@tf.function\n","def distributed_test_step(dataset_inputs):\n","  return strategy.run(test_step, args=(dataset_inputs,))\n","\n","def test_step(inputs):\n","  images, labels = inputs\n","\n","  predictions = model(images, training=False)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss.update_state(t_loss)\n","  test_accuracy.update_state(labels, predictions)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Fkn1fvJatms"},"source":["Training Loop"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGKOigyEZijO","executionInfo":{"status":"ok","timestamp":1633923476158,"user_tz":-420,"elapsed":121394,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"697f174c-9d6f-4762-bc53-cf10839182ed"},"source":["EPOCHS = 10\n","for epoch in range(EPOCHS):\n","  # Do Training\n","  total_loss = 0.0\n","  num_batches = 0\n","  for batch in train_dist_dataset:\n","    total_loss += distributed_train_step(batch)\n","    num_batches += 1\n","  train_loss = total_loss / num_batches\n","\n","  # Do Testing\n","  for batch in test_dist_dataset:\n","    distributed_test_step(batch)\n","\n","  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n","\n","  print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n","\n","  test_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_accuracy.reset_states()"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Epoch 1, Loss: 0.5067647695541382, Accuracy: 81.61499786376953, Test Loss: 0.38638144731521606, Test Accuracy: 85.72999572753906\n","Epoch 2, Loss: 0.3355039656162262, Accuracy: 87.81832885742188, Test Loss: 0.3301256000995636, Test Accuracy: 88.12999725341797\n","Epoch 3, Loss: 0.29091259837150574, Accuracy: 89.29833221435547, Test Loss: 0.3048844337463379, Test Accuracy: 89.3499984741211\n","Epoch 4, Loss: 0.2592480480670929, Accuracy: 90.49166107177734, Test Loss: 0.2822284698486328, Test Accuracy: 89.86000061035156\n","Epoch 5, Loss: 0.23607340455055237, Accuracy: 91.28999328613281, Test Loss: 0.27468159794807434, Test Accuracy: 90.10000610351562\n","Epoch 6, Loss: 0.21498236060142517, Accuracy: 92.03500366210938, Test Loss: 0.25539106130599976, Test Accuracy: 90.77999877929688\n","Epoch 7, Loss: 0.19494254887104034, Accuracy: 92.78500366210938, Test Loss: 0.25166794657707214, Test Accuracy: 91.0199966430664\n","Epoch 8, Loss: 0.18049034476280212, Accuracy: 93.34833526611328, Test Loss: 0.26226773858070374, Test Accuracy: 90.80000305175781\n","Epoch 9, Loss: 0.16321638226509094, Accuracy: 93.98833465576172, Test Loss: 0.2622157037258148, Test Accuracy: 90.80999755859375\n","Epoch 10, Loss: 0.15182660520076752, Accuracy: 94.40333557128906, Test Loss: 0.2706362307071686, Test Accuracy: 90.83999633789062\n"]}]}]}