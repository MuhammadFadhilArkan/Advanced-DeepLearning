{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GradientTapeBasics.ipynb","provenance":[{"file_id":"https://github.com/MuhammadFadhilArkan/Tensorflow_Advance_Techniques/blob/main/2-custom_and_distributed_training/week-1/C2_W1_Lab_2_gradient-tape-basics.ipynb","timestamp":1633856087501}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"id":"uQe_MWjNPQkR","executionInfo":{"status":"ok","timestamp":1633856357326,"user_tz":-420,"elapsed":3471,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["import tensorflow as tf"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"umsBWEgraLUD"},"source":["## Exercise on basics of Gradient Tape\n","\n","Let's explore how you can use [tf.GradientTape()](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to do automatic differentiation."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57Vnn9iIPNh9","executionInfo":{"status":"ok","timestamp":1633856357328,"user_tz":-420,"elapsed":103,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"6e1ae17a-f0e4-4a78-f53f-9810dbd21579"},"source":["# Define a 2x2 array of 1's\n","x = tf.ones((2,2))\n","\n","with tf.GradientTape() as t:\n","    # Record the actions performed on tensor x with `watch`\n","    t.watch(x) \n","\n","    # Define y as the sum of the elements in x\n","    y =  tf.reduce_sum(x)\n","\n","    # Let z be the square of y\n","    z = tf.square(y) \n","\n","# Get the derivative of z wrt the original input tensor x\n","dz_dx = t.gradient(z, x)\n","\n","# Print our result\n","print(dz_dx)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[8. 8.]\n"," [8. 8.]], shape=(2, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"7o1r4emgaLUI"},"source":["### Gradient tape expires after one use, by default\n","\n","If you want to compute multiple gradients, note that by default, GradientTape is not persistent (`persistent=False`).  This means that the GradientTape will expire after you use it to calculate a gradient.\n","\n","To see this, set up gradient tape as usual and calculate a gradient, so that the gradient tape will be 'expired'."]},{"cell_type":"code","metadata":{"id":"s9dfgBMWaLUL","executionInfo":{"status":"ok","timestamp":1633856357329,"user_tz":-420,"elapsed":95,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"00b98b41-03a8-4671-e09e-1998a90b557e","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.constant(3.0)\n","\n","# Notice that persistent is False by default\n","with tf.GradientTape() as t:\n","    t.watch(x)\n","    \n","    # y = x^2\n","    y = x * x\n","    \n","    # z = y^2\n","    z = y * y\n","\n","# Compute dz/dx. 4 * x^3 at x = 3 --> 108.0\n","dz_dx = t.gradient(z, x)\n","print(dz_dx)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(108.0, shape=(), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"kEhyNGr9aLUN"},"source":["#### Gradient tape has expired\n","\n","See what happens if you try to calculate another gradient after you've already used gradient tape once."]},{"cell_type":"code","metadata":{"id":"N5O5T2-2aLUP","executionInfo":{"status":"ok","timestamp":1633856357333,"user_tz":-420,"elapsed":94,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"7d029327-f355-41f0-9ad8-ddf8e99c965f","colab":{"base_uri":"https://localhost:8080/"}},"source":["# If you try to compute dy/dx after the gradient tape has expired:\n","try:\n","    dy_dx = t.gradient(y, x)  # 6.0\n","    print(dy_dx)\n","except RuntimeError as e:\n","    print(\"The error message you get is:\")\n","    print(e)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["The error message you get is:\n","A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"]}]},{"cell_type":"markdown","metadata":{"id":"sSXN3ywcaLUQ"},"source":["### Make the gradient tape persistent\n","To make sure that the gradient tape can be used multiple times, set `persistent=True` "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P12ExatAPqn6","executionInfo":{"status":"ok","timestamp":1633856357335,"user_tz":-420,"elapsed":90,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"4e0ac3d9-e3e3-4e0b-a749-033215904585"},"source":["x = tf.constant(3.0)\n","\n","# Set persistent=True so that you can reuse the tape\n","with tf.GradientTape(persistent=True) as t:\n","    t.watch(x)\n","    \n","    # y = x^2\n","    y = x * x\n","    \n","    # z = y^2\n","    z = y * y\n","\n","# Compute dz/dx. 4 * x^3 at x = 3 --> 108.0\n","dz_dx = t.gradient(z, x)\n","print(dz_dx)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(108.0, shape=(), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"CcZWA7FuaLUS"},"source":["#### Now that it's persistent, you can still reuse this tape!\n","\n","Try calculating a second gradient on this persistent tape."]},{"cell_type":"code","metadata":{"id":"xxHH1ZWlaLUU","executionInfo":{"status":"ok","timestamp":1633856357336,"user_tz":-420,"elapsed":85,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"00846c3c-cea9-4245-b1bc-ae2ba9ea07a6","colab":{"base_uri":"https://localhost:8080/"}},"source":["# You can still compute dy/dx because of the persistent flag.\n","dy_dx = t.gradient(y, x)  # 6.0\n","print(dy_dx)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(6.0, shape=(), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"igcSWBo6aLUV"},"source":["Great! It still works!  Delete the tape variable `t` once you no longer need it."]},{"cell_type":"code","metadata":{"id":"trjL9LObaLUW","executionInfo":{"status":"ok","timestamp":1633856357338,"user_tz":-420,"elapsed":81,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["# Drop the reference to the tape\n","del t  "],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KvGGRYQqaLUZ"},"source":["### Nested Gradient tapes\n","Now let's try computing a higher order derivative by nesting the `GradientTapes:`\n","\n","#### Acceptable indentation of the first gradient calculation\n","Keep in mind that you'll want to make sure that the first gradient calculation of `dy_dx` should occur at least inside the outer `with` block."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxNLeFLlP4qU","executionInfo":{"status":"ok","timestamp":1633856357339,"user_tz":-420,"elapsed":81,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"e9b3bda7-5ead-4a08-9583-dd8015f7b396"},"source":["x = tf.Variable(1.0)\n","\n","with tf.GradientTape() as tape_2:\n","    with tf.GradientTape() as tape_1:\n","        y = x * x * x\n","    \n","    # The first gradient calculation should occur at leaset\n","    # within the outer with block\n","    dy_dx = tape_1.gradient(y, x)\n","d2y_dx2 = tape_2.gradient(dy_dx, x)\n","\n","print(dy_dx)\n","print(d2y_dx2)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(3.0, shape=(), dtype=float32)\n","tf.Tensor(6.0, shape=(), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"OTuKMaxiaLUe"},"source":["The first gradient calculation can also be inside the inner with block."]},{"cell_type":"code","metadata":{"id":"0l2YdbQQaLUg","executionInfo":{"status":"ok","timestamp":1633856357340,"user_tz":-420,"elapsed":77,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"22b29fbf-03f1-4bb5-acf0-15de7a101921","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.Variable(1.0)\n","\n","with tf.GradientTape() as tape_2:\n","    with tf.GradientTape() as tape_1:\n","        y = x * x * x\n","    \n","        # The first gradient calculation can also be within the inner with block\n","        dy_dx = tape_1.gradient(y, x)\n","d2y_dx2 = tape_2.gradient(dy_dx, x)\n","\n","print(dy_dx)\n","print(d2y_dx2)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(3.0, shape=(), dtype=float32)\n","tf.Tensor(6.0, shape=(), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"3-wbSVPDaLUh"},"source":["#### Where not to indent the first gradient calculation\n","If the first gradient calculation is OUTSIDE of the outer `with` block, it won't persist for the second gradient calculation."]},{"cell_type":"code","metadata":{"id":"BrbSKNpeaLUk","executionInfo":{"status":"ok","timestamp":1633856357341,"user_tz":-420,"elapsed":72,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"4007f422-8b2f-4350-b595-2adabfd62e9f","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.Variable(1.0)\n","\n","with tf.GradientTape() as tape_2:\n","    with tf.GradientTape() as tape_1:\n","        y = x * x * x\n","\n","# The first gradient call is outside the outer with block\n","# so the tape will expire after this\n","dy_dx = tape_1.gradient(y, x)\n","\n","# The tape is now expired and the gradient output will be `None`\n","d2y_dx2 = tape_2.gradient(dy_dx, x)\n","\n","print(dy_dx)\n","print(d2y_dx2)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(3.0, shape=(), dtype=float32)\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"RDsTkEE4aLUm"},"source":["Notice how the `d2y_dx2` calculation is now `None`.  The tape has expired.  Also note that this still won't work even if you set persistent=True for both gradient tapes."]},{"cell_type":"code","metadata":{"id":"sDCd81AsaLUp","executionInfo":{"status":"ok","timestamp":1633856357343,"user_tz":-420,"elapsed":69,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"be4801fb-4371-4e34-9cb6-cf769728f5b7","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.Variable(1.0)\n","\n","# Setting persistent=True still won't work\n","with tf.GradientTape(persistent=True) as tape_2:\n","    # Setting persistent=True still won't work\n","    with tf.GradientTape(persistent=True) as tape_1:\n","        y = x * x * x\n","\n","# The first gradient call is outside the outer with block\n","# so the tape will expire after this\n","dy_dx = tape_1.gradient(y, x)\n","\n","# the output will be `None`\n","d2y_dx2 = tape_2.gradient(dy_dx, x)\n","\n","print(dy_dx)\n","print(d2y_dx2)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(3.0, shape=(), dtype=float32)\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"W9RCL_zmaLUx"},"source":["### Proper indentation for the second gradient calculation\n","\n","The second gradient calculation `d2y_dx2` can be indented as much as the first calculation of `dy_dx` but not more."]},{"cell_type":"code","metadata":{"id":"NnUsZ55paLUx","executionInfo":{"status":"ok","timestamp":1633856357345,"user_tz":-420,"elapsed":67,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"9cd619d2-13e2-4f29-94c5-5d4b25ffe9f9","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.Variable(1.0)\n","\n","with tf.GradientTape() as tape_2:\n","    with tf.GradientTape() as tape_1:\n","        y = x * x * x\n","\n","        dy_dx = tape_1.gradient(y, x)\n","        \n","        # this is acceptable\n","        d2y_dx2 = tape_2.gradient(dy_dx, x)\n","\n","print(dy_dx)\n","print(d2y_dx2)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(3.0, shape=(), dtype=float32)\n","tf.Tensor(6.0, shape=(), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"gMv07E2OaLU0"},"source":["This is also acceptable"]},{"cell_type":"code","metadata":{"id":"qvZgXx0iaLU1","executionInfo":{"status":"ok","timestamp":1633856357346,"user_tz":-420,"elapsed":62,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"6e6603b1-14be-471e-8a90-05d5e5d6f1fe","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.Variable(1.0)\n","\n","with tf.GradientTape() as tape_2:\n","    with tf.GradientTape() as tape_1:\n","        y = x * x * x\n","\n","        dy_dx = tape_1.gradient(y, x)\n","        \n","    # this is also acceptable\n","    d2y_dx2 = tape_2.gradient(dy_dx, x)\n","\n","print(dy_dx)\n","print(d2y_dx2)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(3.0, shape=(), dtype=float32)\n","tf.Tensor(6.0, shape=(), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"D9DOVaK3aLU4"},"source":["This is also acceptable"]},{"cell_type":"code","metadata":{"id":"WWXX1vXvaLU6","executionInfo":{"status":"ok","timestamp":1633856357347,"user_tz":-420,"elapsed":59,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"764f2832-0931-4828-b210-d3602a2c0356","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.Variable(1.0)\n","\n","with tf.GradientTape() as tape_2:\n","    with tf.GradientTape() as tape_1:\n","        y = x * x * x\n","\n","        dy_dx = tape_1.gradient(y, x)\n","        \n","# this is also acceptable\n","d2y_dx2 = tape_2.gradient(dy_dx, x)\n","\n","print(dy_dx)\n","print(d2y_dx2)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(3.0, shape=(), dtype=float32)\n","tf.Tensor(6.0, shape=(), dtype=float32)\n"]}]}]}