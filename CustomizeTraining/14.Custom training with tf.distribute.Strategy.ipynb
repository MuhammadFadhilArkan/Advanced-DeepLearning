{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Custom training with tf.distribute.Strategy.ipynb","provenance":[{"file_id":"https://github.com/MuhammadFadhilArkan/Tensorflow_Advance_Techniques/blob/main/2-custom_and_distributed_training/week-4/C2W4_Assignment.ipynb","timestamp":1633924906192}],"collapsed_sections":[]},"coursera":{"schema_names":["TF3C2W4-1","TF3C2W4-2","TF3C2W4-3","TF3C2W4-4"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"id":"dzLKpmZICaWN","executionInfo":{"status":"ok","timestamp":1633925754791,"user_tz":-420,"elapsed":283,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","# Helper libraries\n","import numpy as np\n","import os\n","from tqdm import tqdm"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MM6W__qraV55"},"source":["## Download the dataset"]},{"cell_type":"code","metadata":{"id":"7NsM-Bma5wNw","executionInfo":{"status":"ok","timestamp":1633925755851,"user_tz":-420,"elapsed":690,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"7MqDQO0KCaWS","executionInfo":{"status":"ok","timestamp":1633925755852,"user_tz":-420,"elapsed":63,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n","\n","(train_examples, validation_examples, test_examples), info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True, split = splits, data_dir='data/')\n","\n","num_examples = info.splits['train'].num_examples\n","num_classes = info.features['label'].num_classes"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AXoHhrsbdF3"},"source":["## Create a strategy to distribute the variables and the graph"]},{"cell_type":"markdown","metadata":{"id":"5mVuLZhbem8d"},"source":["How does `tf.distribute.MirroredStrategy` strategy work?\n","\n","*   All the variables and the model graph are replicated on the replicas.\n","*   Input is evenly distributed across the replicas.\n","*   Each replica calculates the loss and gradients for the input it received.\n","*   The gradients are synced across all the replicas by summing them.\n","*   After the sync, the same update is made to the copies of the variables on each replica."]},{"cell_type":"code","metadata":{"id":"F2VeZUWUj5S4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925755856,"user_tz":-420,"elapsed":64,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"3ae636aa-035b-47b7-d45f-8c069947a594"},"source":["# If the list of devices is not specified in the\n","# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n","strategy = tf.distribute.MirroredStrategy()"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"]}]},{"cell_type":"code","metadata":{"id":"ZngeM_2o0_JO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925755857,"user_tz":-420,"elapsed":52,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"750d607e-4b96-4c09-9ba2-088135c9c10a"},"source":["print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of devices: 1\n"]}]},{"cell_type":"markdown","metadata":{"id":"k53F5I_IiGyI"},"source":["## Setup input pipeline"]},{"cell_type":"markdown","metadata":{"id":"0Qb6nDgxiN_n"},"source":["Set some constants, including the buffer size, number of epochs, and the image size."]},{"cell_type":"code","metadata":{"id":"jwJtsCQhHK-E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925755859,"user_tz":-420,"elapsed":46,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"296868b5-32a1-44f4-8cc0-083c4175d771"},"source":["BUFFER_SIZE = num_examples\n","EPOCHS = 10\n","pixels = 224\n","MODULE_HANDLE = 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5'\n","IMAGE_SIZE = (pixels, pixels)\n","print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Using https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5 with input size (224, 224)\n"]}]},{"cell_type":"markdown","metadata":{"id":"rWUl3kUk8D5d"},"source":["Define a function to format the image (resizes the image and scales the pixel values to range from [0,1]."]},{"cell_type":"code","metadata":{"id":"RHGFit478BWD","executionInfo":{"status":"ok","timestamp":1633925755860,"user_tz":-420,"elapsed":34,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["def format_image(image, label):\n","    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n","    return  image, label"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hkfY-kfmg1kA"},"source":["## Set the global batch size (please complete this section)\n","\n","Given the batch size per replica and the strategy, set the global batch size. \n","- The global batch size is the batch size per replica times the number of replicas in the strategy.\n","\n","Use the `num_replicas_in_sync` stored in the [strategy](https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy)."]},{"cell_type":"code","metadata":{"id":"sic_e2NCg1kO","executionInfo":{"status":"ok","timestamp":1633925755862,"user_tz":-420,"elapsed":34,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["# GRADED FUNCTION\n","def set_global_batch_size(batch_size_per_replica, strategy):\n","    '''\n","    Args:\n","        batch_size_per_replica (int) - batch size per replica\n","        strategy (tf.distribute.Strategy) - distribution strategy\n","    '''\n","    \n","    # set the global batch size\n","    global_batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n","    \n","    return global_batch_size"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R3lvdpM6g1kP"},"source":["Set the GLOBAL_BATCH_SIZE with the function that you just defined"]},{"cell_type":"code","metadata":{"id":"2Td76Jmfg1kQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925755865,"user_tz":-420,"elapsed":35,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"bdd35d20-12de-4881-d1f0-4d8535ec52ba"},"source":["BATCH_SIZE_PER_REPLICA = 64\n","GLOBAL_BATCH_SIZE = set_global_batch_size(BATCH_SIZE_PER_REPLICA, strategy)\n","\n","print(GLOBAL_BATCH_SIZE)"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["64\n"]}]},{"cell_type":"markdown","metadata":{"id":"J7fj3GskHC8g"},"source":["Create the datasets using the global batch size and distribute the batches for training, validation and test batches"]},{"cell_type":"code","metadata":{"id":"WYrMNNDhAvVl","executionInfo":{"status":"ok","timestamp":1633925755866,"user_tz":-420,"elapsed":29,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE_PER_REPLICA).prefetch(1)\n","validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE_PER_REPLICA).prefetch(1)\n","test_batches = test_examples.map(format_image).batch(1)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J3v4mnBNg1kb"},"source":["## Define the distributed datasets\n","\n","Create the distributed datasets using `experimental_distribute_dataset()` of the [Strategy](https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy) class and pass in the training batches.\n","- Do the same for the validation batches and test batches."]},{"cell_type":"code","metadata":{"id":"5IscJ-Y7g1kf","executionInfo":{"status":"ok","timestamp":1633925755872,"user_tz":-420,"elapsed":35,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["# GRADED FUNCTION\n","def distribute_datasets(strategy, train_batches, validation_batches, test_batches):\n","    \n","    train_dist_dataset = strategy.experimental_distribute_dataset(train_batches)\n","    val_dist_dataset = strategy.experimental_distribute_dataset(validation_batches)\n","    test_dist_dataset = strategy.experimental_distribute_dataset(test_batches)\n","    \n","    return train_dist_dataset, val_dist_dataset, test_dist_dataset"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zNVDyvOYg1kg"},"source":["Call the function that you just defined to get the distributed datasets."]},{"cell_type":"code","metadata":{"id":"YS3ML5qeg1kh","executionInfo":{"status":"ok","timestamp":1633925755876,"user_tz":-420,"elapsed":38,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["train_dist_dataset, val_dist_dataset, test_dist_dataset = distribute_datasets(strategy, train_batches, validation_batches, test_batches)"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rI99AUdXg1kj"},"source":["Take a look at the type of the train_dist_dataset"]},{"cell_type":"code","metadata":{"id":"8AmMS4t2g1km","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925756483,"user_tz":-420,"elapsed":643,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"d6774cc9-feeb-46df-9bae-c01b33ca3af7"},"source":["print(type(train_dist_dataset))\n","print(type(val_dist_dataset))\n","print(type(test_dist_dataset))"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n","<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n","<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n"]}]},{"cell_type":"markdown","metadata":{"id":"v-Mty1Gvg1kr"},"source":["Also get familiar with a single batch from the train_dist_dataset:\n","- Each batch has 64 features and labels"]},{"cell_type":"code","metadata":{"id":"SelRscEug1ks","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925756790,"user_tz":-420,"elapsed":314,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"26faebaa-6f31-4466-beb6-d4746e29a1ae"},"source":["# Take a look at a single batch from the train_dist_dataset\n","for x in train_dist_dataset:\n","    # do nothing, just get one batch x\n","    break\n","    \n","print(f\"x is a tuple that contains {len(x)} values \")\n","print(f\"x[0] contains the features, and has shape {x[0].shape}\")\n","print(f\"  so it has {x[0].shape[0]} examples in the batch, each is an image that is {x[0].shape[1:]}\")\n","print(f\"x[1] contains the labels, and has shape {x[1].shape}\")"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["x is a tuple that contains 2 values \n","x[0] contains the features, and has shape (64, 224, 224, 3)\n","  so it has 64 examples in the batch, each is an image that is (224, 224, 3)\n","x[1] contains the labels, and has shape (64,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"bAXAo_wWbWSb"},"source":["## Create the model\n","\n","Use the Model Subclassing API to create model `ResNetModel` as a subclass of `tf.keras.Model`."]},{"cell_type":"code","metadata":{"id":"9ODch-OFCaW4","executionInfo":{"status":"ok","timestamp":1633925756791,"user_tz":-420,"elapsed":13,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["class ResNetModel(tf.keras.Model):\n","    def __init__(self, classes):\n","        super(ResNetModel, self).__init__()\n","        self._feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n","                                                 trainable=False) \n","        self._classifier = tf.keras.layers.Dense(classes, activation='softmax')\n","\n","    def call(self, inputs):\n","        x = self._feature_extractor(inputs)\n","        x = self._classifier(x)\n","        return x"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zpu1iNpjg1kw"},"source":["Create a checkpoint directory to store the checkpoints (the model's weights during training)."]},{"cell_type":"code","metadata":{"id":"9iagoTBfijUz","executionInfo":{"status":"ok","timestamp":1633925756792,"user_tz":-420,"elapsed":13,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["# Create a checkpoint directory to store the checkpoints.\n","checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e-wlFFZbP33n"},"source":["## Define the loss function\n","\n","define the `loss_object` and `compute_loss` within the `strategy.scope()`.\n","- `loss_object` will be used later to calculate the loss on the test set.\n","- `compute_loss` will be used later to calculate the average loss on the training data."]},{"cell_type":"code","metadata":{"id":"R144Wci782ix","executionInfo":{"status":"ok","timestamp":1633925756793,"user_tz":-420,"elapsed":13,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["with strategy.scope():\n","    # Set reduction to `NONE` so we can do the reduction afterwards and divide by\n","    # global batch size.\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","        reduction=tf.keras.losses.Reduction.NONE)\n","    # or loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n","    def compute_loss(labels, predictions):\n","        per_example_loss = loss_object(labels, predictions)\n","        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n","\n","    test_loss = tf.keras.metrics.Mean(name='test_loss')"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w8y54-o9T2Ni"},"source":["## Define the metrics to track loss and accuracy\n","\n","These metrics track the test loss and training and test accuracy. \n","- Use `.result()` to get the accumulated statistics at any time, for example, `train_accuracy.result()`."]},{"cell_type":"code","metadata":{"id":"zt3AHb46Tr3w","executionInfo":{"status":"ok","timestamp":1633925756795,"user_tz":-420,"elapsed":14,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["with strategy.scope():\n","    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","        name='train_accuracy')\n","    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","        name='test_accuracy')"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iuKuNXPORfqJ"},"source":["## Instantiate the model, optimizer, and checkpoints\n","\n","This code is created within the `strategy.scope()`.\n","- Instantiate the ResNetModel, passing in the number of classes\n","- Create an instance of the Adam optimizer.\n","- Create a checkpoint for this model and its optimizer."]},{"cell_type":"code","metadata":{"id":"OrMmakq5EqeQ","executionInfo":{"status":"ok","timestamp":1633925761966,"user_tz":-420,"elapsed":5184,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["# model and optimizer must be created under `strategy.scope`.\n","with strategy.scope():\n","    model = ResNetModel(classes=num_classes)\n","    optimizer = tf.keras.optimizers.Adam()\n","    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0WB89fng1k9"},"source":["## Training loop\n","\n","Define a regular training step and test step, which could work without a distributed strategy.  Use `strategy.run` to apply these functions in a distributed manner.\n","- Define `train_step` and `test_step` inside another function `train_testp_step_fns`, which will then return these two functions.\n","\n","### Define train_step\n","Within the strategy's scope, define `train_step(inputs)`\n","- `inputs` will be a tuple containing `(images, labels)`.\n","- Create a gradient tape block.\n","- Within the gradient tape block: \n","  - Call the model, passing in the images and setting training to be `True` .\n","  - Call the `compute_loss` function (defined earlier) to compute the training loss.\n","  - Use the gradient tape to calculate the gradients.\n","  - Use the optimizer to update the weights using the gradients.\n","  \n","### Define test_step\n","Also within the strategy's scope, define `test_step(inputs)`\n","- `inputs` is a tuple containing `(images, labels)`.\n","  - Call the model, passing in the images and set training to `False`, because the model is not going to train on the test data.\n","  - Use the `loss_object`, which will compute the test loss.  Check `compute_loss`, defined earlier, to see what parameters to pass into `loss_object`.\n","  - Next, update `test_loss` (the running test loss) with the `t_loss` (the loss for the current batch).\n","  - Also update the `test_accuracy`."]},{"cell_type":"code","metadata":{"id":"zUQ_nAP1MtA9","executionInfo":{"status":"ok","timestamp":1633925761967,"user_tz":-420,"elapsed":30,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["def train_test_step_fns(strategy, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy):\n","    with strategy.scope():\n","        def train_step(inputs):\n","            images, labels = inputs\n","\n","            with tf.GradientTape() as tape:\n","                predictions = model(images, training=True)\n","                loss = compute_loss(labels, predictions)\n","\n","            gradients = tape.gradient(loss, model.trainable_variables)\n","            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","            train_accuracy.update_state(labels, predictions)\n","            return loss \n","\n","        def test_step(inputs):\n","            images, labels = inputs\n","            \n","            predictions = model(images, training=False)\n","            t_loss = loss_object(labels, predictions)\n","\n","            test_loss.update_state(t_loss)\n","            test_accuracy.update_state(labels, predictions)\n","        \n","        return train_step, test_step"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kzuX9KFMg1k_"},"source":["Use the `train_test_step_fns` function to produce the `train_step` and `test_step` functions."]},{"cell_type":"code","metadata":{"id":"fZPmlWWCg1lA","executionInfo":{"status":"ok","timestamp":1633925761968,"user_tz":-420,"elapsed":28,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["train_step, test_step = train_test_step_fns(strategy, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy)"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oFCMcBEog1lD"},"source":["## Distributed training and testing\n","\n","The `train_step` and `test_step` could be used in a non-distributed, regular model training.  To apply them in a distributed way, you'll use [strategy.run](https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy#run).\n","\n","`distributed_train_step`\n","- Call the `run` function of the `strategy`, passing in the train step function (which defined earlier), as well as the arguments that go in the train step function.\n","- The run function is defined like this `run(fn, args=() )`.  \n","  - `args` will take in the dataset inputs\n","\n","`distributed_test_step`\n","- Similar to training, the distributed test step will use the `run` function of your strategy, taking in the test step function as well as the dataset inputs that go into the test step function."]},{"cell_type":"markdown","metadata":{"id":"-d4CuaUIg1lD"},"source":["- each batch in `train_dist_dataset` is tuple with two values:\n","  - a batch of features\n","  - a batch of labels.\n"]},{"cell_type":"code","metadata":{"id":"utQLz8o2g1lE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925761969,"user_tz":-420,"elapsed":27,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"fcb8e8dc-b088-4975-c667-475fc428cfc1"},"source":["#See various ways of passing in the inputs \n","\n","def fun1(args=()):\n","    print(f\"number of arguments passed is {len(args)}\")\n","    \n","    \n","list_of_inputs = [1,2]\n","print(\"When passing in args=list_of_inputs:\")\n","fun1(args=list_of_inputs)\n","print()\n","print(\"When passing in args=(list_of_inputs)\")\n","fun1(args=(list_of_inputs))\n","print()\n","print(\"When passing in args=(list_of_inputs,)\")\n","fun1(args=(list_of_inputs,))"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["When passing in args=list_of_inputs:\n","number of arguments passed is 2\n","\n","When passing in args=(list_of_inputs)\n","number of arguments passed is 2\n","\n","When passing in args=(list_of_inputs,)\n","number of arguments passed is 1\n"]}]},{"cell_type":"markdown","metadata":{"id":"madiNT4mg1lH"},"source":["Notice that depending on how `list_of_inputs` is passed to `args` affects whether `fun1` sees one or two positional arguments.  \n","- If there is an error message about positional arguments when running the training code later, please check how you're passing in the inputs to `run`."]},{"cell_type":"code","metadata":{"id":"7D9bsVIpg1lM","executionInfo":{"status":"ok","timestamp":1633925761970,"user_tz":-420,"elapsed":25,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["def distributed_train_test_step_fns(strategy, train_step, test_step, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy):\n","    with strategy.scope():\n","        @tf.function\n","        def distributed_train_step(dataset_inputs):\n","            per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n","            return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n","                                   axis=None)\n","\n","        @tf.function\n","        def distributed_test_step(dataset_inputs):\n","            return strategy.run(test_step, args = (dataset_inputs,))\n","    \n","        return distributed_train_step, distributed_test_step"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykIVnCX3g1lO"},"source":["Call the function that you just defined to get the distributed train step function and distributed test step function."]},{"cell_type":"code","metadata":{"id":"cDsSSgEHg1lO","executionInfo":{"status":"ok","timestamp":1633925761971,"user_tz":-420,"elapsed":23,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["distributed_train_step, distributed_test_step = distributed_train_test_step_fns(strategy, train_step, test_step, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy)"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cbciugb4g1lP"},"source":["**An important note before you continue:** \n","\n","The following sections will guide you through how to train your model and save it to a .zip file.\n","\n","After training your model, you can download it as a .zip file and upload it back to the platform to know how well it performed.  However, training your model takes around 20 minutes within the Coursera environment. Because of this, there are two methods to train your model:\n","\n","**Method 1**\n","\n","If 20 mins is too long for you, we recommend to download this notebook and upload it to [Colab](https://colab.research.google.com/) to finish the training in a GPU-enabled runtime. If you decide to do this, these are the steps to follow:\n","\n","- Save this notebok.\n","- Click the `jupyter` logo on the upper left corner of the window. This will take you to the Jupyter workspace.\n","- Select this notebook and click `Shutdown`.\n","- Once the notebook is shutdown, you can go ahead and download it.\n","- Head over to [Colab](https://colab.research.google.com/) and select the `upload` tab and upload your notebook.\n","- Before running any cell go into `Runtime` --> `Change Runtime Type` and make sure that `GPU` is enabled.\n","- Run all of the cells in the notebook. After training, follow the rest of the instructions of the notebook to download your model.\n","\n","**Method 2**\n","\n","If you prefer to wait the 20 minutes, keep going through this notebook. Once you are done, follow these steps:\n","- Click the `jupyter` logo on the upper left corner of the window. This will take you to the jupyter filesystem.\n","- In the filesystem you should see a file named `mymodel.zip`. Go ahead and download it.\n","\n","Independent of the method you choose, you should end up with a `mymodel.zip` file which can be uploaded for evaluation after this assignment. Once again, this is optional but we strongly encourage you to do it as it is a lot of fun. \n","\n","With this out of the way, let's continue.\n","\n","\n","\n","## Run the distributed training in a loop\n","\n","You'll now use a for-loop to go through the desired number of epochs and train the model in a distributed manner.\n","In each epoch:\n","- Loop through each distributed training set\n","  - For each training batch, call `distributed_train_step` and get the loss.\n","- After going through all training batches, calculate the training loss as the average of the batch losses.\n","- Loop through each batch of the distributed test set.\n","  - For each test batch, run the distributed test step. The test loss and test accuracy are updated within the test step function.\n","- Print the epoch number, training loss, training accuracy, test loss and test accuracy.\n","- Reset the losses and accuracies before continuing to another epoch."]},{"cell_type":"code","metadata":{"id":"gX975dMSNw0e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925885356,"user_tz":-420,"elapsed":123407,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"32cc705a-71d8-42bf-f35a-8d03d1ebd73d"},"source":["# Running this cell in Coursera takes around 20 mins\n","with strategy.scope():\n","    for epoch in range(EPOCHS):\n","        # TRAIN LOOP\n","        total_loss = 0.0\n","        num_batches = 0\n","        for x in tqdm(train_dist_dataset):\n","            total_loss += distributed_train_step(x)\n","            num_batches += 1\n","        train_loss = total_loss / num_batches\n","\n","        # TEST LOOP\n","        for x in test_dist_dataset:\n","            distributed_test_step(x)\n","\n","        template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n","                    \"Test Accuracy: {}\")\n","        print (template.format(epoch+1, train_loss,\n","                               train_accuracy.result()*100, test_loss.result(),\n","                               test_accuracy.result()*100))\n","\n","        test_loss.reset_states()\n","        train_accuracy.reset_states()\n","        test_accuracy.reset_states()"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["13it [00:48,  3.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 4.569979667663574, Accuracy: 4.289216041564941, Test Loss: 3.982581615447998, Test Accuracy: 14.705883026123047\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Loss: 2.6733460426330566, Accuracy: 45.4656867980957, Test Loss: 2.948396682739258, Test Accuracy: 44.11764907836914\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Loss: 1.6200103759765625, Accuracy: 81.49510192871094, Test Loss: 2.462257146835327, Test Accuracy: 51.960784912109375\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4, Loss: 1.0233803987503052, Accuracy: 92.1568603515625, Test Loss: 2.1319193840026855, Test Accuracy: 54.90196228027344\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5, Loss: 0.6990830302238464, Accuracy: 95.83332824707031, Test Loss: 1.919468641281128, Test Accuracy: 58.82353210449219\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6, Loss: 0.5087203979492188, Accuracy: 97.91667175292969, Test Loss: 1.7982202768325806, Test Accuracy: 60.78431701660156\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7, Loss: 0.3868792653083801, Accuracy: 98.52941131591797, Test Loss: 1.7158503532409668, Test Accuracy: 62.74510192871094\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8, Loss: 0.3030306100845337, Accuracy: 99.63235473632812, Test Loss: 1.6536372900009155, Test Accuracy: 64.70588684082031\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9, Loss: 0.2453528344631195, Accuracy: 99.75489807128906, Test Loss: 1.6046382188796997, Test Accuracy: 64.70588684082031\n"]},{"output_type":"stream","name":"stderr","text":["13it [00:05,  2.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10, Loss: 0.20159055292606354, Accuracy: 99.87745666503906, Test Loss: 1.5677629709243774, Test Accuracy: 65.68627166748047\n"]}]},{"cell_type":"markdown","metadata":{"id":"Z1YvXqOpwy08"},"source":["Things to note in the example above:\n","\n","* We are iterating over the `train_dist_dataset` and `test_dist_dataset` using  a `for x in ...` construct.\n","* The scaled loss is the return value of the `distributed_train_step`. This value is aggregated across replicas using the `tf.distribute.Strategy.reduce` call and then across batches by summing the return value of the `tf.distribute.Strategy.reduce` calls.\n","* `tf.keras.Metrics` should be updated inside `train_step` and `test_step` that gets executed by `tf.distribute.Strategy.experimental_run_v2`.\n","*`tf.distribute.Strategy.experimental_run_v2` returns results from each local replica in the strategy, and there are multiple ways to consume this result. You can do `tf.distribute.Strategy.reduce` to get an aggregated value. You can also do `tf.distribute.Strategy.experimental_local_results` to get the list of values contained in the result, one per local replica.\n"]},{"cell_type":"markdown","metadata":{"id":"WEaNCzYQvFqo"},"source":["# Save the Model for submission\n","\n","You'll get a saved model of this trained model.\n","\n","## Step 1: Save the model as a SavedModel\n","This code will save your model as a SavedModel"]},{"cell_type":"code","metadata":{"id":"1zAlTlRxrqFu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633925893611,"user_tz":-420,"elapsed":8286,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"5e26e183-06f4-4599-9473-72e8ce23128c"},"source":["model_save_path = \"./tmp/mymodel/1/\"\n","tf.saved_model.save(model, model_save_path)"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ./tmp/mymodel/1/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: ./tmp/mymodel/1/assets\n"]}]},{"cell_type":"markdown","metadata":{"id":"e0Zfmx6LvTJA"},"source":["## Step 2: Zip the SavedModel Directory into /mymodel.zip\n","\n","This code will zip your saved model directory contents into a single file.\n","\n","If you are on colab, you can use the file browser pane to the left of colab to find `mymodel.zip`. Right click on it and select 'Download'.\n","\n","If the download fails because you aren't allowed to download multiple files from colab, check out the guidance here: https://ccm.net/faq/32938-google-chrome-allow-websites-to-perform-simultaneous-downloads\n","\n","It's a large file, so it might take some time to download."]},{"cell_type":"code","metadata":{"id":"gMuo2wQls41l","executionInfo":{"status":"ok","timestamp":1633925901192,"user_tz":-420,"elapsed":7591,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["import os\n","import zipfile\n","\n","def zipdir(path, ziph):\n","    # ziph is zipfile handle\n","    for root, dirs, files in os.walk(path):\n","        for file in files:\n","            ziph.write(os.path.join(root, file))\n","\n","zipf = zipfile.ZipFile('./mymodel.zip', 'w', zipfile.ZIP_DEFLATED)\n","zipdir('./tmp/mymodel/1/', zipf)\n","zipf.close()"],"execution_count":46,"outputs":[]}]}